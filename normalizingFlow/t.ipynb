{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim, tensor, Tensor\n",
    "from torchdiffeq import odeint, odeint_adjoint\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{cases}\n",
    "\\sigma(x) = \\log (\\exp(-x) + \\exp(x)) \\\\\n",
    "\\sigma'(x) = \\tanh(x) \\\\\n",
    "\\sigma''(x) = 1 - \\tanh^2(x)\n",
    "\\end{cases}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def antidrivtanh(x):\n",
    "#     return torch.abs(x) + torch.log(1+torch.exp(-2.0 * torch.abs(x)))\n",
    "\n",
    "def antidrivtanh(x):\n",
    "    return torch.log(torch.exp(-x) + torch.exp(x))\n",
    "\n",
    "def derivtanh(x):\n",
    "    return 1 - torch.tanh(x).pow(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ResNet：This module is used to convert $\\mathbb{R}^{d+1}$ into $\\mathbb{R}^{m}$:\n",
    "  1. The first layer is used to convert the dimension of data.\n",
    "  2. The layers except for first is used to extract feature in $\\mathbb{R}^{m}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, d, m, nTh=2):\n",
    "        assert nTh >=2, \"nTh should not less than 2\"\n",
    "        super(ResNet, self).__init__()\n",
    "        self.d = d\n",
    "        self.m = m\n",
    "        self.nTh = nTh\n",
    "        \n",
    "        self.layers = nn.ModuleList([nn.Linear(d+1,m, bias=True)]  + [nn.Linear(m,m, bias=True) for _ in range(nTh-1)])\n",
    "        self.act = antidrivtanh\n",
    "        self.h = 1.0 / (self.nTh - 1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.act(self.layers[0].forward(x))\n",
    "\n",
    "        for i in range(1, self.nTh):\n",
    "            x = x + self.h * self.act(self.layers[i].forward(x))\n",
    "\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Phi.forward()`\n",
    "\t$$ \\begin{split} \\Phi(\\mathbf{s};\\boldsymbol{\\theta})  = \\mathbf{w}^{T} N(\\mathbf{s};\\boldsymbol{\\theta}_{N}) + \\frac{1}{2} \\mathbf{s}^{T}(A^{T}A)\\mathbf{s} + \\mathbf{b}^{T}\\mathbf{s} + c,\\\\ \\text{where} \\quad \\boldsymbol{\\theta} =(\\mathbf{w},\\boldsymbol{\\theta}_{N}, A,\\mathbf{b},c) \\end{split} $$\n",
    "- `Phi.trHess`: Compute the trace\n",
    "\t1. 梯度计算:\n",
    "\t\t$$ \\nabla_{\\mathbf{s}}\\Phi(\\mathbf{s};\\boldsymbol{\\theta}) = \\nabla_{\\mathbf{s}}N(\\mathbf{s};\\boldsymbol{\\theta}_{N})\\mathbf{w} + (A^{T}A)\\mathbf{s} + \\mathbf{b} $$\n",
    "\t\t其中，$\\nabla_{\\mathbf{s}}N(\\mathbf{s};\\boldsymbol{\\theta}_N)\\mathbf{w}$ 可用如下的方法进行计算\n",
    "\t\t$$ \\begin{split} &\\mathbf{z}_{1} = \\mathbf{w} + h K_{1}^{T} \\text{diag}(\\sigma'(K_{1} \\mathbf{u}_{0}+\\mathbf{b}_{1})) \\mathbf{w},\\\\ &\\mathbf{z}_{0} = K_{0}^{T}\\text{diag}(\\sigma'(K_{0}\\mathbf{s}+\\mathbf{b}_{0}))\\mathbf{z}_{1},\\quad \\text{where}\\\\ &\\nabla_{\\mathbf{s}}n(\\mathbf{s};\\boldsymbol{\\theta}_{n})\\mathbf{w} = \\mathbf{z}_{0} \\end{split} $$\n",
    "\t2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Phi(nn.Module):\n",
    "    def __init__(self, nTh, m, d, r=10, alph=[1.0]*5):\n",
    "        super(Phi,self).__init__()\n",
    "\n",
    "        self.m = m\n",
    "        self.nTh = nTh\n",
    "        self.d = d\n",
    "        self.alph = alph\n",
    "\n",
    "        r = min(r,d+1)\n",
    "\n",
    "        self.A = nn.Parameter(torch.zeros(r,d+1), requires_grad=True)\n",
    "        self.A = nn.init.xavier_normal_(self.A)\n",
    "        self.c = nn.Linear(d+1, 1, bias=True)\n",
    "        self.w = nn.Linear(m , 1, bias=False)\n",
    "\n",
    "        self.N = ResNet(d,m, nTh=nTh)\n",
    "\n",
    "        self.w.weight.data = torch.ones(self.w.weight.data.shape)\n",
    "        self.c.weight.data = torch.ones(self.c.weight.data.shape)\n",
    "        self.c.bias.data = torch.ones(self.c.bias.data.shape)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        symA = torch.mul(self.A.T,self.A)\n",
    "\n",
    "        return self.w(self.N(x)) + 1/2 * torch.sum(torch.matmul(x, symA) * x, dim=1, keepdims=True) + self.c(x)\n",
    "    \n",
    "    def trHess(self, x, justGrad=False):\n",
    "        N = self.N\n",
    "        m = N.layers[0].weight_shape[0]\n",
    "        nex = x.shape[0]\n",
    "        d = x.shape[1] -1\n",
    "        symA = torch.matmul(self.A.T, self.A)\n",
    "\n",
    "        u = []  # store the result of each layer in ResNet\n",
    "        z = N.nTh * [None]\n",
    "        opening = N.layers[0].forward(x)\n",
    "\n",
    "        u.append(N.act(opening))\n",
    "        feat = u[0]\n",
    "\n",
    "        for i in range(1, N.nTh):\n",
    "            feat = feat + N.h * N.act(N.layers[i].forward(feat))\n",
    "            u.append(feat)\n",
    "\n",
    "        tanhopen = torch.tanh(opening)\n",
    "\n",
    "        for i in range(N.nTh-1, 0, -1):\n",
    "            if i == N.nTh-1:\n",
    "                term = self.w.weight.T\n",
    "            else:\n",
    "                term = z[i+1]\n",
    "            \n",
    "            z[i] = term + N.h * torch.mm(N.layers[i].weight.T, torch.tanh(N.layers[i].forward(u[i-1])).T * term)\n",
    "\n",
    "        z[0] = torch.mm(N.layers[0].weight.T, tanhopen.T * z[1])\n",
    "        grad = z[0] + torch.mm(symA, x.T) + self.c.weight.T\n",
    "\n",
    "        if justGrad:\n",
    "            return grad.T\n",
    "        \n",
    "        Kopen = N.layers[0].weight[:,0:d]\n",
    "        temp = derivtanh(opening.T) * z[1]\n",
    "        trH = torch.sum(temp.reshape(m, -1, nex) * Kopen.unsqueeze(2).pow(2), dim=(0,1))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2514, 0.5387, 0.8071]],\n",
       "\n",
       "        [[0.8981, 0.0797, 0.6337]],\n",
       "\n",
       "        [[0.4484, 0.0544, 0.7297]]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.reshape(3,-1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.randn(3,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8469, -0.1457, -0.2025, -0.4517, -1.9758, -1.0002, -0.7658, -1.2111,\n",
       "          0.8555, -0.1719],\n",
       "        [ 0.1901, -0.5251,  0.2471,  1.8723,  0.1929, -0.3041, -0.9909, -0.7169,\n",
       "          0.1969,  1.3466],\n",
       "        [ 0.9016,  0.1166, -0.4051,  1.4957,  0.8242,  0.6152,  0.1457, -2.0950,\n",
       "          0.5188,  0.2074]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.7451,  9.9124,  6.2011,  3.0812,  3.2062, -7.0861,  1.2512, -9.9082,\n",
       "         0.9248, -6.4054])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x @ A.T @ A "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Phi(2, 10, 2)(torch.randn(2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t = nn.ModuleList([nn.Linear(3,2, bias=True)]  + [nn.Linear(2,2, bias=True) for _ in range(3-2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=2, out_features=2, bias=True)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3446,  0.0425, -1.4836, -0.4734],\n",
       "        [-0.3858,  0.1519,  0.0171, -0.6214],\n",
       "        [-0.1361,  1.9312, -0.8237, -0.0834]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4962, 1.5356],\n",
       "        [1.4549, 1.7337],\n",
       "        [1.5968, 1.7456]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = ResNet(3, 2)\n",
    "t(torch.randn(3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Linear(in_features=3, out_features=2, bias=True),\n",
       " Linear(in_features=3, out_features=3, bias=True)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
